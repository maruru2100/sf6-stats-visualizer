import streamlit as st
import datetime
import time
import os
import threading
import random
from sqlalchemy import text
from config import TARGET_ID, DATABASE_URL, ENV_ERROR, JST, LOG_FILE, FULL_SCREENSHOT_PATH
from database import init_db, engine
from scraper import scrape_sf6, update_public_url

# --- åˆæœŸåŒ– ---
init_db()

def get_now_jst(): return datetime.datetime.now(JST)

def write_log(message):
    now = get_now_jst().strftime("%Y-%m-%d %H:%M:%S")
    formatted_msg = f"[{now}] {message}"
    print(formatted_msg)
    try:
        with open(LOG_FILE, "a") as f: f.write(formatted_msg + "\n")
    except: pass
    if "log_messages" not in st.session_state: st.session_state.log_messages = ""
    st.session_state.log_messages += formatted_msg + "\n"

def run_all_users(max_pages=2):
    """ã€é †æ¬¡å®Ÿè¡Œã€‘ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹æœ‰åŠ¹ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å…¨å“¡ã‚’é †ç•ªã«å®Ÿè¡Œ"""
    try:
        with engine.connect() as conn:
            users = conn.execute(text("SELECT user_code, player_name FROM target_users WHERE is_active = TRUE")).fetchall()
        
        if not users:
            write_log("âš ï¸ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        write_log(f"ğŸ‘¥ è¨ˆ {len(users)} åã®å·¡å›ã‚’é †æ¬¡é–‹å§‹ã—ã¾ã™ã€‚")
        for i, u in enumerate(users):
            scrape_sf6(u.user_code, u.player_name, write_log, max_pages=max_pages)
            
            if i < len(users) - 1:
                wait_sec = random.randint(15, 30)
                write_log(f"â˜• è² è·è»½æ¸›ã®ãŸã‚ {wait_sec}ç§’ å¾…æ©Ÿã—ã¦æ¬¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ç§»ã‚Šã¾ã™...")
                time.sleep(wait_sec)
        write_log("âœ¨ å…¨å“¡ã®å·¡å›ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        write_log(f"ğŸ’¥ å…¨å“¡å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def background_worker():
    last_run = ""
    while True:
        if ENV_ERROR: break
        now_dt = get_now_jst()
        today_str = now_dt.strftime("%Y-%m-%d")
        current_time_total_minutes = now_dt.hour * 60 + now_dt.minute
        
        try:
            with engine.connect() as conn:
                res = conn.execute(text("SELECT value FROM scraper_config WHERE key = 'run_times'"))
                row = res.fetchone()
                raw_times = row[0].split(",") if row else ["09:00", "21:00"]
                run_times = []
                for t in raw_times:
                    t = t.strip()
                    if len(t) == 4 and ":" in t: t = "0" + t
                    run_times.append(t)
        except: run_times = ["09:00", "21:00"]

        for t_str in run_times:
            try:
                h, m = map(int, t_str.split(":"))
                target_total_minutes = h * 60 + m
                if target_total_minutes <= current_time_total_minutes < target_total_minutes + 60:
                    if last_run != today_str + t_str:
                        write_log(f"â° å®šæœŸå·¡å›é–‹å§‹ (è¨­å®š: {t_str})")
                        run_all_users(max_pages=2) 
                        last_run = today_str + t_str
                        break
            except: continue
        time.sleep(60)

# --- UI ---
st.set_page_config(page_title="SF6 Stats Manager", layout="wide")

# èƒŒæ™¯ã‚¹ãƒ¬ãƒƒãƒ‰ã®é–‹å§‹
if "worker_thread_started" not in st.session_state:
    if not any(t.name == "BackgroundWorker" for t in threading.enumerate()):
        threading.Thread(target=background_worker, name="BackgroundWorker", daemon=True).start()
    st.session_state.worker_thread_started = True

with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    
    # å¤–éƒ¨å…¬é–‹ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸŒ å¤–éƒ¨å…¬é–‹ç®¡ç†")
    if st.button("ğŸ”„ å…¬é–‹URLã‚’æœ€æ–°ã«æ›´æ–°", use_container_width=True, help="Cloudflare Tunnelã‹ã‚‰æœ€æ–°ã®ãƒ©ãƒ³ãƒ€ãƒ URLã‚’å–å¾—ã—ã¦DBã‚’æ›´æ–°ã—ã¾ã™"):
        # ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã›ãšã€URLå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ã ã‘ã‚’å‹•ã‹ã™
        update_public_url(write_log)
        st.success("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.divider()

    st.subheader("ğŸ‘¥ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†")
    with st.expander("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ /æ›´æ–°"):
        new_uid = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ (10æ¡)", key="input_uid")
        new_pname = st.text_input("è¡¨ç¤ºå", key="input_pname")
        new_note = st.text_area("ãƒ¡ãƒ¢", key="input_note")
        
        if st.button("ç™»éŒ²/ä¸Šæ›¸ã"):
            if not new_uid or not new_pname:
                st.error("IDã¨è¡¨ç¤ºåã¯å¿…é ˆã§ã™")
            else:
                with engine.connect() as conn:
                    conn.execute(text("""
                        INSERT INTO target_users (user_code, player_name, note) 
                        VALUES (:uid, :name, :note) ON CONFLICT (user_code) 
                        DO UPDATE SET player_name=EXCLUDED.player_name, note=EXCLUDED.note
                    """), {"uid": new_uid, "name": new_pname, "note": new_note})
                    conn.commit()
                st.session_state.input_uid = ""
                st.session_state.input_pname = ""
                st.session_state.input_note = ""
                st.success("âœ… ä¿å­˜ã—ã¾ã—ãŸ")
                time.sleep(1)
                st.rerun()

    try:
        with engine.connect() as conn:
            res = conn.execute(text("SELECT value FROM scraper_config WHERE key = 'run_times'"))
            row = res.fetchone()
            db_times = row[0] if row else "09:00,21:00"
    except: db_times = "09:00,21:00"
    
    st.subheader("â° è‡ªå‹•å·¡å›ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«")
    new_times = st.text_input("å®Ÿè¡Œæ™‚é–“ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)", value=db_times)
    if st.button("è¨­å®šã‚’ä¿å­˜", use_container_width=True):
        with engine.connect() as conn:
            conn.execute(text("UPDATE scraper_config SET value = :val WHERE key = 'run_times'"), {"val": new_times})
            conn.commit()
        st.success("âœ… ä¿å­˜å®Œäº†"); time.sleep(1); st.rerun()

st.title("ğŸ¥Š SF6 æˆ¦ç¸¾ï¼†çµ±è¨ˆåé›†ã‚·ã‚¹ãƒ†ãƒ ")
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("å®Ÿè¡Œ")
    with engine.connect() as conn:
        users_list = conn.execute(text("SELECT user_code, player_name FROM target_users")).fetchall()
    
    if users_list:
        selected_u = st.selectbox("å˜ç™ºå®Ÿè¡Œå¯¾è±¡", options=users_list, format_func=lambda x: f"{x.player_name} ({x.user_code})")
        max_p = st.slider("å·¡å›ãƒšãƒ¼ã‚¸æ•°", 1, 50, 5)
        
        c_btn1, c_btn2 = st.columns(2)
        with c_btn1:
            if st.button("ğŸš€ é¸æŠãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿å®Ÿè¡Œ", use_container_width=True):
                scrape_sf6(selected_u.user_code, selected_u.player_name, write_log, max_pages=max_p)
                st.rerun()
        with c_btn2:
            if st.button("ğŸ”„ å…¨å“¡åˆ†ã‚’é †æ¬¡å®Ÿè¡Œ", use_container_width=True):
                run_all_users(max_pages=max_p)
                st.rerun()
    else:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")

    st.divider()
    st.subheader("æœ€æ–°ã®ãƒ­ã‚°")
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r") as f:
            lines = f.readlines()
            st.text_area("å®Ÿè¡Œå±¥æ­´ (æœ€æ–°50ä»¶)", value="".join(lines[-50:]), height=400)

with col2:
    st.subheader("ç™»éŒ²ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§")
    with engine.connect() as conn:
        df_users = conn.execute(text("SELECT player_name as åå‰, user_code as ID, note as ãƒ¡ãƒ¢, is_active as æœ‰åŠ¹ FROM target_users")).fetchall()
        if df_users:
            st.table(df_users)
        else:
            st.write("ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã„ã¾ã›ã‚“ã€‚")
            
    if os.path.exists(FULL_SCREENSHOT_PATH):
        st.divider()
        st.subheader("æœ€æ–°ã®ã‚­ãƒ£ãƒ—ãƒãƒ£")
        st.image(FULL_SCREENSHOT_PATH, caption="Last Scrape View")