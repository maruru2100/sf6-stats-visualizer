import streamlit as st
import datetime
import time
import os
import threading
from sqlalchemy import text
from config import TARGET_ID, DATABASE_URL, ENV_ERROR, JST, LOG_FILE, FULL_SCREENSHOT_PATH
from database import init_db, engine
from scraper import scrape_sf6

# --- ÂàùÊúüÂåñ ---
init_db()

def get_now_jst():
    return datetime.datetime.now(JST)

def write_log(message):
    now = get_now_jst().strftime("%Y-%m-%d %H:%M:%S")
    formatted_msg = f"[{now}] {message}"
    print(formatted_msg)
    try:
        with open(LOG_FILE, "a") as f:
            f.write(formatted_msg + "\n")
    except: pass
    if "log_messages" not in st.session_state:
        st.session_state.log_messages = ""
    st.session_state.log_messages += formatted_msg + "\n"

def background_worker():
    last_run = ""
    while True:
        if ENV_ERROR: break
        now_dt = get_now_jst()
        today_str = now_dt.strftime("%Y-%m-%d")
        current_time_total_minutes = now_dt.hour * 60 + now_dt.minute
        
        try:
            with engine.connect() as conn:
                res = conn.execute(text("SELECT value FROM scraper_config WHERE key = 'run_times'"))
                row = res.fetchone()
                raw_times = row[0].split(",") if row else ["09:00", "21:00"]
                run_times = []
                for t in raw_times:
                    t = t.strip()
                    if len(t) == 4 and ":" in t: t = "0" + t
                    run_times.append(t)
        except: run_times = ["09:00", "21:00"]

        for t_str in run_times:
            try:
                h, m = map(int, t_str.split(":"))
                target_total_minutes = h * 60 + m
                if target_total_minutes <= current_time_total_minutes < target_total_minutes + 60:
                    if last_run != today_str + t_str:
                        write_log(f"‚è∞ ÂÆöÊúüÂ∑°ÂõûÈñãÂßã (Ë®≠ÂÆö: {t_str})")
                        scrape_sf6(TARGET_ID, write_log, max_pages=2)
                        last_run = today_str + t_str
                        break
            except: continue
        time.sleep(60)

# --- UI ---
st.set_page_config(page_title="SF6 Stats Manager", layout="wide")

with st.sidebar:
    st.title("‚öôÔ∏è Ë®≠ÂÆö")
    with engine.connect() as conn:
        res = conn.execute(text("SELECT value FROM scraper_config WHERE key = 'run_times'"))
        row = res.fetchone()
        db_times = row[0] if row else "09:00,21:00"
    st.subheader("‚è∞ Ëá™ÂãïÂ∑°Âõû„Çπ„Ç±„Ç∏„É•„Éº„É´")
    new_times = st.text_input("ÂÆüË°åÊôÇÈñì („Ç´„É≥„ÉûÂå∫Âàá„Çä)", value=db_times)
    if st.button("Ë®≠ÂÆö„Çí‰øùÂ≠ò", use_container_width=True):
        with engine.connect() as conn:
            conn.execute(text("UPDATE scraper_config SET value = :val WHERE key = 'run_times'"), {"val": new_times})
            conn.commit()
        st.success("‚úÖ ‰øùÂ≠òÂÆå‰∫Ü"); time.sleep(1); st.rerun()

if "worker_thread_started" not in st.session_state:
    if not any(t.name == "BackgroundWorker" for t in threading.enumerate()):
        threading.Thread(target=background_worker, name="BackgroundWorker", daemon=True).start()
    st.session_state.worker_thread_started = True

st.title("ü•ä SF6 Êà¶Á∏æÔºÜÁµ±Ë®àÂèéÈõÜ„Ç∑„Çπ„ÉÜ„É†")
col1, col2 = st.columns([1, 1])
with col1:
    st.subheader("ÊâãÂãïÂÆüË°å")
    current_target = st.text_input("„Çø„Éº„Ç≤„ÉÉ„Éà„É¶„Éº„Ç∂„ÉºID", value=TARGET_ID)
    max_p = st.slider("Â∑°Âõû„Éö„Éº„Ç∏Êï∞", 1, 50, 5)
    if st.button("üöÄ ‰ªä„Åô„ÅêÊúÄÊñ∞„Éá„Éº„Çø„ÇíÂèñÂæó", use_container_width=True):
        scrape_sf6(current_target, write_log, max_pages=max_p); st.rerun()
    st.divider(); st.subheader("„É≠„Ç∞")
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r") as f:
            st.text_area("ÂÆüË°åÂ±•Ê≠¥ (ÊúÄÊñ∞50‰ª∂)", value="".join(f.readlines()[-50:]), height=300)
with col2:
    st.subheader("ÂâçÂõû„ÅÆÁä∂ÊÖã")
    if os.path.exists(FULL_SCREENSHOT_PATH): st.image(FULL_SCREENSHOT_PATH)